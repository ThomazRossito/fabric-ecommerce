# Fabric notebook source

# METADATA ********************

# META {
# META   "kernel_info": {
# META     "name": "synapse_pyspark"
# META   },
# META   "dependencies": {
# META     "lakehouse": {
# META       "default_lakehouse": "ff4c5f56-7490-4a4b-a0b1-115bd42aaaf2",
# META       "default_lakehouse_name": "TARN_LH_DEV",
# META       "default_lakehouse_workspace_id": "e1e7a468-d318-49d0-b238-287c09020d88",
# META       "known_lakehouses": [
# META         {
# META           "id": "ff4c5f56-7490-4a4b-a0b1-115bd42aaaf2"
# META         }
# META       ]
# META     }
# META   }
# META }

# MARKDOWN ********************

# # üèóÔ∏è Orchestrator DAG: Pipeline Medallion Architecture

# MARKDOWN ********************

# ## Descri√ß√£o
# 
# Pipeline de orquestra√ß√£o completo seguindo **Arquitetura Medallion** com DAG estruturada, depend√™ncias.
# 
# ### Funcionalidades Principais:
# 
# 1. **üîó Depend√™ncias Gerenciadas** - Execu√ß√£o ordenada respeitando depend√™ncias
# 2. **‚ö° Paralelismo Inteligente** - Dimens√µes processam em paralelo
# 3. **üìä Rastreabilidade** - Logs e m√©tricas de cada etapa
# 4. **üéØ Pipeline Completo** - Transient ‚Üí Bronze ‚Üí Silver ‚Üí Gold
# 
# ### Arquitetura do Pipeline:
# 
# ```
# TRANSIENT (Dados Brutos)
#     ‚îÇ
#     ‚îú‚îÄ> [BRONZE] notebook_bronze
#     ‚îÇ       ‚îÇ
#     ‚îÇ       ‚îú‚îÄ> [SILVER] notebook_silver
#     ‚îÇ       ‚îÇ       ‚îÇ
#     ‚îÇ       ‚îÇ       ‚îú‚îÄ> [GOLD - Dimens√µes] (PARALELO)
#     ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ> dim_clientes
#     ‚îÇ       ‚îÇ       ‚îÇ       ‚îú‚îÄ> dim_data
#     ‚îÇ       ‚îÇ       ‚îÇ       ‚îî‚îÄ> dim_produtos
#     ‚îÇ       ‚îÇ       ‚îÇ               ‚îÇ
#     ‚îÇ       ‚îÇ       ‚îÇ               ‚îî‚îÄ> [GOLD - Fato]
#     ‚îÇ       ‚îÇ       ‚îÇ                       ‚îî‚îÄ> fato_vendas
#     ‚îÇ       ‚îÇ       ‚îÇ
#     ‚îÇ       ‚îÇ       ‚îî‚îÄ> Camada Silver (Dados Limpos)
#     ‚îÇ       ‚îÇ
#     ‚îÇ       ‚îî‚îÄ> Camada Bronze (Dados Brutos + Auditoria)
#     ‚îÇ
#     ‚îî‚îÄ> Camada Transient (Landing Zone)
# ```
# 
# ### Estrutura de Depend√™ncias:
# 
# | Activity | Depende De | Paralelismo |
# |----------|-----------|-------------|
# | Bronze | (nenhum) | In√≠cio |
# | Silver | Bronze | Sequencial |
# | dim_clientes | Silver | Paralelo |
# | dim_data | Silver | Paralelo |
# | dim_produtos | Silver | Paralelo |
# | fato_vendas | dim_clientes, dim_data, dim_produtos | Ap√≥s dimens√µes |
# 
# ### Caracter√≠sticas T√©cnicas:
# 
# - ‚úÖ **Timeout por Notebook**: 300s (5 minutos)
# - ‚úÖ **Isolamento**: Cada notebook em processo separado
# - ‚úÖ **Resili√™ncia**: Falha em dimens√£o n√£o para outras
# - ‚úÖ **Visualiza√ß√£o DAG**: Grafo visual das depend√™ncias
# 
# ### Performance Esperada:
# 
# | Cen√°rio | Tempo Sequencial | Tempo DAG | Ganho |
# |---------|-----------------|-----------|-------|
# | Sem paralelismo | ~30 min | ~30 min | 1x |
# | Com paralelismo (dim) | ~30 min | ~20 min | 1.5x |
# 
# **Ganho**: Dimens√µes processam simultaneamente.
# 
# ## Depend√™ncias:
# 
# - **PySpark**: DataFrame API
# - **mssparkutils**: APIs nativas do Fabric
# - **Logger customizado**: tarn_notebook_logger
# 
# ## Notebooks Requeridos:
# 
# 1. `notebook_bronze` - Ingest√£o Transient ‚Üí Bronze
# 2. `notebook_silver` - Transforma√ß√£o Bronze ‚Üí Silver
# 3. `notebook_gold_dim_clientes` - Dimens√£o Clientes
# 4. `notebook_gold_dim_data` - Dimens√£o Data
# 5. `notebook_gold_dim_produtos` - Dimens√£o Produtos
# 6. `notebook_gold_fato_vendas` - Fato Vendas
# 
# ---


# MARKDOWN ********************

# ## üë®‚Äçüíª **Autor** üë®‚Äçüíª
# 
# > **Estruturado por:** <span style="font-size: 1.5em;">Thomaz Antonio Rossito Neto</span>
# 
# <b><span style="font-size: 1.2em; font-style: italic;">üèÜ Profissional Certificado Databricks</span></b>
# 
# <div style="display: flex; flex-wrap: wrap; align-items: center; margin-bottom: 20px;">
#     <img src="https://api.accredible.com/v1/frontend/credential_website_embed_image/badge/125134719" width="135" style="margin-right: -25px;"/>
#     <img src="https://api.accredible.com/v1/frontend/credential_website_embed_image/badge/167127257" width="135" style="margin-right: -25px;"/>
#     <img src="https://api.accredible.com/v1/frontend/credential_website_embed_image/badge/169321258" width="135" style="margin-right: -25px;"/>
#     <img src="https://api.accredible.com/v1/frontend/credential_website_embed_image/badge/125134780" width="135" style="margin-right: -25px;"/>
#     <img src="https://api.accredible.com/v1/frontend/credential_website_embed_image/badge/157011932" width="135"/>
# </div>
# 
# <div style="display: flex; flex-wrap: wrap; align-items: center;">
#     <img src="https://images.credly.com/images/af27ef78-6967-4082-b6ce-8111b1af47e1/MTA_Database_Fundamentals-01.png" width="115" style="margin-right: 10px;"/>
#     <img src="https://images.credly.com/size/340x340/images/70eb1e3f-d4de-4377-a062-b20fb29594ea/azure-data-fundamentals-600x600.png" width="115" style="margin-right: 10px;"/>
#     <img src="https://images.credly.com/images/bb4a3c26-9f24-4913-9ae5-7331a3d657a6/MCSA-Data-Engineering-with-Azure_2019.png" width="115" style="margin-right: 10px;"/>
#     <img src="https://images.credly.com/images/7e080b6a-0494-4b3e-a016-23f73566495f/MCSE-Data-Management-and-Analytics_2019.png" width="115"/>
# </div>
# 
# <br>
# 
# [Certifica√ß√µes Databricks](https://credentials.databricks.com/profile/thomazantoniorossitoneto39867/wallet)              
# [Certifica√ß√µes Microsoft](https://www.credly.com/users/thomaz-antonio-rossito-neto/badges#credly)
# 
# ---
# 
# ### Data de Cria√ß√£o
# ##### Janeiro 2026


# MARKDOWN ********************

# ## üì¶ Importa√ß√£o de Bibliotecas
# 
# Importa todas as depend√™ncias necess√°rias para orquestra√ß√£o da DAG Medallion.
# 
# ### Bibliotecas Utilizadas:
# 
# - **json**: Parsing de resultados dos notebooks
# - **time**: Medi√ß√£o de performance do pipeline
# - **datetime.timedelta**: Formata√ß√£o de dura√ß√µes
# - **mssparkutils**: APIs nativas do Fabric


# CELL ********************

import json
import time
from datetime import timedelta
from notebookutils import mssparkutils

print("="*80)
print("üèóÔ∏è ORCHESTRATOR DAG - PIPELINE MEDALLION COMPLETO üèóÔ∏è")
print("="*80)
print("üìä Arquitetura: Transient ‚Üí Bronze ‚Üí Silver ‚Üí Gold")
print("üîó Depend√™ncias: Gerenciadas automaticamente")
print("="*80)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ---
# ## ‚öôÔ∏è Configura√ß√£o do Pipeline
# 
# ### Par√¢metros Configur√°veis:
# 
# #### TIMEOUT
# Timeout m√°ximo por c√©lula de cada notebook (segundos).
# - **Padr√£o**: 300s (5 minutos)
# - **Bronze**: Pode precisar de mais (muitos arquivos)
# - **Silver**: Transforma√ß√µes podem demorar
# - **Gold**: Geralmente r√°pido (agrega√ß√µes)
# 
# #### DISPLAY_DAG
# Habilita visualiza√ß√£o gr√°fica da DAG.
# - **True**: Mostra grafo com depend√™ncias
# - **False**: Sem visualiza√ß√£o (mais r√°pido)
# 
# ### Notebooks do Pipeline:
# 
# **IMPORTANTE**: Todos os notebooks listados DEVEM existir no workspace.
# 
# ---

# CELL ********************

# =============================================================================
# CONFIGURA√á√ïES GLOBAIS
# =============================================================================

TIMEOUT = 300           # 5 minutos por c√©lula
DISPLAY_DAG = True      # Visualizar grafo

# =============================================================================
# NOTEBOOKS DO PIPELINE
# =============================================================================

# Camada Bronze
NOTEBOOK_BRONZE = "notebook_bronze"

# Camada Silver
NOTEBOOK_SILVER = "notebook_silver"

# Camada Gold - Dimens√µes
NOTEBOOK_DIM_CLIENTES = "notebook_gold_dim_clientes"
NOTEBOOK_DIM_DATA = "notebook_gold_dim_data"
NOTEBOOK_DIM_PRODUTOS = "notebook_gold_dim_produtos"

# Camada Gold - Fato
NOTEBOOK_FATO_VENDAS = "notebook_gold_fato_vendas"

# =============================================================================
# LOG DE CONFIGURA√á√ïES
# =============================================================================

print(f"‚öôÔ∏è Configura√ß√µes: ‚öôÔ∏è")

print("\nüìã Configura√ß√µes do Pipeline:")
print(f"   Timeout: {TIMEOUT}s ({TIMEOUT/60:.1f} min)")
print(f"   Visualiza√ß√£o DAG: {'‚úÖ Habilitada' if DISPLAY_DAG else '‚ùå Desabilitada'}")
print(f"\nüìì Notebooks:")
print(f"   Bronze: {NOTEBOOK_BRONZE}")
print(f"   Silver: {NOTEBOOK_SILVER}")
print(f"   Dimens√µes: {NOTEBOOK_DIM_CLIENTES}, {NOTEBOOK_DIM_DATA}, {NOTEBOOK_DIM_PRODUTOS}")
print(f"   Fato: {NOTEBOOK_FATO_VENDAS}")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ---
# ## üèóÔ∏è Constru√ß√£o da DAG com Depend√™ncias
# 
# ### Objetivo:
# 
# Construir estrutura DAG completa com todas as activities, depend√™ncias.
# 
# ### Estrutura de uma Activity:
# 
# ```python
# {
#     "name": "bronze",                    # Identificador √∫nico
#     "path": "notebook_bronze",           # Nome do notebook
#     "timeoutPerCellInSeconds": 300,      # Timeout
#     "args": {...},                       # Par√¢metros (opcional)
#     "dependencies": ["bronze"]           # Lista de depend√™ncias (opcional)
# }
# ```
# 
# ### Fluxo de Depend√™ncias:
# 
# 1. **Bronze**: Executa primeiro (sem depend√™ncias)
# 2. **Silver**: Aguarda Bronze concluir
# 3. **Dimens√µes**: Aguardam Silver, executam em PARALELO
# 4. **Fato**: Aguarda TODAS as 3 dimens√µes conclu√≠rem
# 
# 
# ### Paralelismo:
# 
# - **Dimens√µes**: Como todas dependem apenas de Silver, executam simultaneamente
# - **Fato**: Aguarda barreira (todas dimens√µes conclu√≠das)
# 
# ---


# CELL ********************

print("üèóÔ∏è Construindo DAG Medallion... üèóÔ∏è")

# =============================================================================
# ESTRUTURA DA DAG
# =============================================================================

dag = {
    "activities": [
        
        # =====================================================================
        # CAMADA BRONZE (Sem depend√™ncias - Executa primeiro)
        # =====================================================================
        {
            "name": "dag_bronze",
            "path": NOTEBOOK_BRONZE,
            "timeoutPerCellInSeconds": TIMEOUT,
            "args": {
                "pipe_name": "dag_bronze",
                "note_name": NOTEBOOK_BRONZE,
                "schema_atcual": "bronze"
            },
            # Sem dependencies - executa primeiro
        },
        
        # =====================================================================
        # CAMADA SILVER (Depende de Bronze)
        # =====================================================================
        {
            "name": "dag_silver",
            "path": NOTEBOOK_SILVER,
            "timeoutPerCellInSeconds": TIMEOUT,
            "args": {
                "pipe_name": "dag_silver",
                "note_name": NOTEBOOK_SILVER,
                "schema_atcual": "silver"
            },
            "dependencies": ["dag_bronze"]  # Aguarda Bronze
        },
        
        # =====================================================================
        # CAMADA GOLD - DIMENS√ïES (Dependem de Silver, executam em PARALELO)
        # =====================================================================
        
        # Dimens√£o Clientes
        {
            "name": "dag_gold_dim_clientes",
            "path": NOTEBOOK_DIM_CLIENTES,
            "timeoutPerCellInSeconds": TIMEOUT,
            "args": {
                "pipe_name": "dag_gold_dim_clientes",
                "note_name": NOTEBOOK_DIM_CLIENTES,
                "schema_atcual": "gold"
            },
            "dependencies": ["dag_silver"]  # Aguarda Silver
        },
        
        # Dimens√£o Data
        {
            "name": "dag_gold_dim_data",
            "path": NOTEBOOK_DIM_DATA,
            "timeoutPerCellInSeconds": TIMEOUT,
            "args": {
                "pipe_name": "dag_gold_dim_data",
                "note_name": NOTEBOOK_DIM_DATA,
                "schema_atcual": "gold"
            },
            "dependencies": ["dag_silver"]  # Aguarda Silver
        },
        
        # Dimens√£o Produtos
        {
            "name": "dag_gold_dim_produtos",
            "path": NOTEBOOK_DIM_PRODUTOS,
            "timeoutPerCellInSeconds": TIMEOUT,
            "args": {
                "pipe_name": "dag_gold_dim_produtos",
                "note_name": NOTEBOOK_DIM_PRODUTOS,
                "schema_atcual": "gold"
            },
            "dependencies": ["dag_silver"]  # Aguarda Silver
        },
        
        # =====================================================================
        # CAMADA GOLD - FATO (Depende de TODAS as dimens√µes)
        # =====================================================================
        {
            "name": "dag_gold_fato_vendas",
            "path": NOTEBOOK_FATO_VENDAS,
            "timeoutPerCellInSeconds": TIMEOUT,
            "args": {
                "pipe_name": "dag_gold_fato_vendas",
                "note_name": NOTEBOOK_FATO_VENDAS,
                "schema_atcual": "gold"
            },
            # Aguarda TODAS as 3 dimens√µes
            "dependencies": [
                "dag_gold_dim_clientes",
                "dag_gold_dim_data",
                "dag_gold_dim_produtos"
            ]
        }
    ]
}

# =============================================================================
# VALIDA√á√ÉO E LOG
# =============================================================================

num_activities = len(dag['activities'])

print("\nüèóÔ∏è  DAG Medallion Constru√≠da:")
print(f"   ‚úÖ Total de activities: {num_activities}")
print("\n   Estrutura de execu√ß√£o:")
print("   1. Bronze (sequencial: 1)")
print("      ‚Üì")
print("   2. Silver (sequencial: 1)")
print("      ‚Üì")
print("   3. Dimens√µes (paralelo: 3)")
print("      ‚îú‚îÄ dim_clientes")
print("      ‚îú‚îÄ dim_data")
print("      ‚îî‚îÄ dim_produtos")
print("         ‚Üì")
print("   4. Fato (sequencial: 1)")
print("      ‚îî‚îÄ fato_vendas")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ---
# ## üöÄ Execu√ß√£o da DAG Medallion
# 
# ### Objetivo:
# 
# Executar DAG completa respeitando depend√™ncias, paralelismo.
# 
# ### Como o Fabric Executa:
# 
# 1. **Analisa depend√™ncias**: Constr√≥i grafo de execu√ß√£o
# 2. **Executa Bronze**: Primeiro notebook (sem depend√™ncias)
# 3. **Aguarda Bronze**: Silver espera conclus√£o
# 4. **Executa Silver**: Ap√≥s Bronze concluir
# 5. **Aguarda Silver**: Dimens√µes esperam
# 6. **Executa Dimens√µes em PARALELO**: 3 notebooks simult√¢neos
# 7. **Aguarda TODAS dimens√µes**: Barreira para Fato
# 8. **Executa Fato**: Ap√≥s todas dimens√µes
# 
# ---

# CELL ********************

print("\n" + "="*80)
print("üöÄ INICIANDO PIPELINE MEDALLION üöÄ")
print("="*80)
print(f"üìä Activities: {num_activities}")
print(f"üîó Cont√©m depend√™ncias configuradas")
print(f"‚è≥ Aguarde... Execu√ß√£o em progresso...")
print("="*80 + "\n")

print("üöÄ Executando DAG Medallion...")

# =============================================================================
# EXECU√á√ÉO DA DAG
# =============================================================================

start_time = time.time()

try:
    # Executa DAG com depend√™ncias
    dag_result = mssparkutils.notebook.runMultiple(
        dag,
        {"displayDAGViaGraphviz": DISPLAY_DAG}
    )
    
    total_duration = time.time() - start_time
    
    print("\n" + "="*40)
    print("‚úÖ PIPELINE MEDALLION CONCLU√çDO")
    print("="*40)
    print(f"‚è±Ô∏è  Tempo total: {str(timedelta(seconds=int(total_duration)))} ({total_duration:.2f}s)")
    print("="*40 + "\n")
    
except Exception as e:
    fail_duration = time.time() - start_time
    
    print(f"‚ùå FALHA CR√çTICA: {str(e)}")
    
    print("\n" + "="*80)
    print("‚ùå ERRO CR√çTICO NO PIPELINE")
    print("="*80)
    print(f"Erro: {str(e)}")
    print(f"Tempo at√© falha: {fail_duration:.2f}s")
    print("="*80)
    
    raise

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ---
# ## üìä Processamento de Resultados
# 
# ### Objetivo:
# 
# Extrair e consolidar resultados de todas as activities (Bronze, Silver, Dimens√µes, Fato).
# 
# ### Status Poss√≠veis:
# 
# - **Succeeded**: Activity conclu√≠da com sucesso
# 
# ---

# CELL ********************

import json
import ast

print("üìä Monta vari√°veis para relat√≥rio...")

expected_activities = [
    "dag_bronze", "dag_silver", "dag_gold_dim_clientes", 
    "dag_gold_dim_data", "dag_gold_dim_produtos", "dag_gold_fato_vendas"
]

results = {}

for activity_name in expected_activities:
    if activity_name in dag_result:
        val = dag_result[activity_name]
        
        # Extrair a string de sa√≠da (pode estar dentro de 'exitVal' ou ser a pr√≥pria string)
        exit_content = val.get("exitVal", str(val)) if isinstance(val, dict) else str(val)
        
        try:
            # Tenta literal_eval primeiro, pois aceita aspas simples (formato Python)
            # Isso resolve: {'success': True} que o json.loads rejeita
            r = ast.literal_eval(exit_content)
        except:
            try:
                # Fallback para JSON caso o conte√∫do venha com aspas duplas
                r = json.loads(exit_content)
            except Exception as e:
                r = {"success": False, "error": f"Erro de leitura: {str(e)}", "status": "Failed"}
        
        results[activity_name] = r
    else:
        results[activity_name] = {"success": False, "error": "N√£o executado", "status": "Skipped"}

# Reatribuindo para as vari√°veis do seu relat√≥rio
bronze_result = results.get("dag_bronze", {})
silver_result = results.get("dag_silver", {})
dim_clientes_result = results.get("dag_gold_dim_clientes", {})
dim_data_result = results.get("dag_gold_dim_data", {})
dim_produtos_result = results.get("dag_gold_dim_produtos", {})
fato_vendas_result = results.get("dag_gold_fato_vendas", {})

print(f"‚úÖ Vari√°veis criadas com Sucesso!!!")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ---
# ## üìã Relat√≥rio Final Consolidado
# 
# Relat√≥rio completo do pipeline Medallion com todas as m√©tricas e status.
# 
# ### Se√ß√µes:
# 
# 1. **Resumo Executivo**: Totais e taxa de sucesso
# 2. **Performance**: Tempo total e por camada
# 3. **Status por Camada**: Bronze, Silver, Gold (Dim + Fato)
# 4. **Depend√™ncias**: Quais aguardaram quais
# 5. **Conclus√£o**: Status final do pipeline
# 
# ---

# CELL ********************

# =============================================================================
# RELAT√ìRIO FINAL
# =============================================================================

print("\n" + "="*80)
print("üìä RELAT√ìRIO FINAL - PIPELINE MEDALLION")
print("="*80)

# =============================================================================
# SE√á√ÉO 1: RESUMO EXECUTIVO
# =============================================================================

# Recalcular sucessos/falhas baseado no objeto processado
successes = sum(1 for r in results.values() if r.get("success") == True)
failures = len(results) - successes

print("\nüìà RESUMO EXECUTIVO:")
print("-" * 80)
print(f"   Total de activities: {len(results)}")
print(f"   ‚úÖ Sucessos: {successes}")
print(f"   ‚ùå Falhas: {failures}")
print(f"   Taxa de sucesso: {(successes/len(results)*100):.1f}%")

# =============================================================================
# SE√á√ÉO 2: PERFORMANCE
# =============================================================================

print("\n‚ö° PERFORMANCE:")
print("-" * 80)
print(f"   Tempo total: {str(timedelta(seconds=int(total_duration)))} ({total_duration:.2f}s)")

# Tempo por camada (se dispon√≠vel)
if bronze_result.get("duration"):
    print(f"   Bronze: {bronze_result['duration']:.2f}s")
if silver_result.get("duration"):
    print(f"   Silver: {silver_result['duration']:.2f}s")

# Tempo das dimens√µes (paralelo)
dim_durations = []
if dim_clientes_result.get("duration"):
    dim_durations.append(dim_clientes_result['duration'])
if dim_data_result.get("duration"):
    dim_durations.append(dim_data_result['duration'])
if dim_produtos_result.get("duration"):
    dim_durations.append(dim_produtos_result['duration'])

if dim_durations:
    print(f"   Dimens√µes (paralelo): {max(dim_durations):.2f}s (max de {len(dim_durations)} dimens√µes)")

if fato_vendas_result.get("duration"):
    print(f"   Fato Vendas: {fato_vendas_result['duration']:.2f}s")

# =============================================================================
# SE√á√ÉO 3: STATUS POR CAMADA
# =============================================================================

print("\nüìä STATUS POR CAMADA:")
print("-" * 80)

# BRONZE
print("\n   ü•â BRONZE:")
if bronze_result.get("success"):
    print(f"      Status: ‚úÖ Succeeded")
    if bronze_result.get("records"):
        print(f"      Registros: {bronze_result['records']:,}")
else:
    status = bronze_result.get("status", "Failed")
    error = bronze_result.get("error", "Unknown error")
    print(f"      Status: ‚ùå {status}")
    print(f"      Erro: {error}")

# SILVER
print("\n   ü•à SILVER:")
if silver_result.get("success"):
    print(f"      Status: ‚úÖ Succeeded")
    if silver_result.get("records"):
        print(f"      Registros: {silver_result['records']:,}")
else:
    status = silver_result.get("status", "Failed")
    error = silver_result.get("error", "Unknown error")
    print(f"      Status: ‚ùå {status}")
    print(f"      Erro: {error}")

# GOLD - DIMENS√ïES
print("\n   ü•á GOLD - DIMENS√ïES (Processadas em paralelo):")

# Clientes
print("\n      üìä dim_clientes:")
if dim_clientes_result.get("success"):
    print(f"         Status: ‚úÖ Succeeded")
    if dim_clientes_result.get("records"):
        print(f"         Registros: {dim_clientes_result['records']:,}")
else:
    status = dim_clientes_result.get("status", "Failed")
    error = dim_clientes_result.get("error", "Unknown error")
    print(f"         Status: ‚ùå {status}")
    print(f"         Erro: {error}")

# Data
print("\n      üìÖ dim_data:")
if dim_data_result.get("success"):
    print(f"         Status: ‚úÖ Succeeded")
    if dim_data_result.get("records"):
        print(f"         Registros: {dim_data_result['records']:,}")
else:
    status = dim_data_result.get("status", "Failed")
    error = dim_data_result.get("error", "Unknown error")
    print(f"         Status: ‚ùå {status}")
    print(f"         Erro: {error}")

# Produtos
print("\n      üì¶ dim_produtos:")
if dim_produtos_result.get("success"):
    print(f"         Status: ‚úÖ Succeeded")
    if dim_produtos_result.get("records"):
        print(f"         Registros: {dim_produtos_result['records']:,}")
else:
    status = dim_produtos_result.get("status", "Failed")
    error = dim_produtos_result.get("error", "Unknown error")
    print(f"         Status: ‚ùå {status}")
    print(f"         Erro: {error}")

# GOLD - FATO
print("\n   ü•á GOLD - FATO:")
print("\n      üí∞ fato_vendas:")
if fato_vendas_result.get("success"):
    print(f"         Status: ‚úÖ Succeeded")
    if fato_vendas_result.get("records"):
        print(f"         Registros: {fato_vendas_result['records']:,}")
else:
    status = fato_vendas_result.get("status", "Failed")
    error = fato_vendas_result.get("error", "Unknown error")
    print(f"         Status: ‚ùå {status}")
    print(f"         Erro: {error}")

# =============================================================================
# SE√á√ÉO 4: ESTRUTURA DE DEPEND√äNCIAS
# =============================================================================

print("\nüîó ESTRUTURA DE DEPEND√äNCIAS:")
print("-" * 80)
print("   bronze ‚Üí (sem depend√™ncias)")
print("   silver ‚Üí aguardou: bronze")
print("   gold_dim_clientes ‚Üí aguardou: silver")
print("   gold_dim_data ‚Üí aguardou: silver")
print("   gold_dim_produtos ‚Üí aguardou: silver")
print("   gold_fato_vendas ‚Üí aguardou: gold_dim_clientes, gold_dim_data, gold_dim_produtos")

# =============================================================================
# SE√á√ÉO 5: STATUS FINAL
# =============================================================================

print("\n" + "="*80)

if failures == 0:
    print("üéâ PIPELINE MEDALLION CONCLU√çDO COM SUCESSO TOTAL!")
    print("="*80)
    print(f"‚úÖ Todas as {len(results)} activities executadas com sucesso")
    print(f"‚è±Ô∏è  Tempo total: {str(timedelta(seconds=int(total_duration)))}")
    print("\nüìä Camadas processadas:")
    print("   ‚úÖ Bronze (Transient ‚Üí Bronze)")
    print("   ‚úÖ Silver (Bronze ‚Üí Silver)")
    print("   ‚úÖ Gold - Dimens√µes (Silver ‚Üí Dimens√µes)")
    print("   ‚úÖ Gold - Fato (Dimens√µes ‚Üí Fato)")
    
    print(f"üéâ Pipeline Medallion: Sucesso total em {total_duration:.2f}s")
    
else:
    print("‚ö†Ô∏è  PIPELINE MEDALLION CONCLU√çDO COM FALHAS")
    print("="*80)
    print(f"‚úÖ Sucessos: {successes}/{len(results)}")
    print(f"‚ùå Falhas: {failures}/{len(results)}")
    print(f"\nüîç RECOMENDA√á√ïES:")
    print("   1. Revisar erros nas activities que falharam")
    print("   2. Verificar logs individuais de cada notebook")
    print("   3. Corrigir problemas identificados")
    print("   4. Re-executar pipeline completo")
    
    print(f"‚ùå Pipeline com {failures} falhas")

print("="*80)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ## üìä Monitoramento: Log de Execu√ß√£o do Pipeline Medallion


# CELL ********************

import json
import time

# 1. Empacota o dicion√°rio local em uma string JSON
results_json = json.dumps(results)

# Configura√ß√µes do Retry
max_tentativas = 1
tempo_espera_segundos = 15

print("üöÄ Disparando logs para o notebook de monitoramento...")

for tentativa in range(1, max_tentativas + 1):
    try:
        print(f"‚ñ∂Ô∏è Executando notebook de log (Tentativa {tentativa}/{max_tentativas})...")
        
        # Chama o outro notebook
        mssparkutils.notebook.run("notebook_monitoramento_log", 60, {"dag_results_raw": results_json})
        
        # Se chegou nesta linha sem dar erro, o run() funcionou. 
        print("‚úÖ Envio de logs finalizado com sucesso!!!")
        
        # O comando 'break' interrompe o loop for imediatamente, evitando as pr√≥ximas tentativas.
        break 

    except Exception as e:
        print(f"‚ö†Ô∏è Falha na tentativa {tentativa}: {e}")
        
        # Se ainda n√£o for a √∫ltima tentativa, aguarda antes de tentar de novo
        if tentativa < max_tentativas:
            print(f"‚è≥ Aguardando {tempo_espera_segundos} segundos antes da pr√≥xima tentativa...")
            time.sleep(tempo_espera_segundos)
        else:
            print("‚ùå Todas as tentativas falharam. O log n√£o foi gravado na tabela.")
            # Descomente a linha abaixo se voc√™ quiser que o Notebook Principal TAMB√âM 
            # d√™ erro/falhe caso o envio de log n√£o funcione de jeito nenhum.
            # raise e

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

df = spark.sql("SELECT * FROM TARN_LH_DEV.monitoramento.tb_monitoramento_log LIMIT 1000")
display(df)

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# CELL ********************

# try:
#     print("üöÄ Enviando logs para monitoramento.tb_monitoramento_log...")

#     # Transformamos o dicion√°rio em uma String JSON
#     results_json = json.dumps(results)
#     mssparkutils.notebook.run("notebook_monitoramento_log", 60, {"dag_results_raw": results_json})

#     print("‚úÖ Logs para monitoramento.tb_monitoramento_log sucesso!!! ‚úÖ")

# except Exception as e:
#     print(f"‚ö†Ô∏è Aviso: Falha ao gravar log de monitoramento: {e}")

# METADATA ********************

# META {
# META   "language": "python",
# META   "language_group": "synapse_pyspark"
# META }

# MARKDOWN ********************

# ---
# ## üìñ Documenta√ß√£o de Uso
# 
# ### Pr√©-requisitos:
# 
# **Notebooks necess√°rios no workspace**:
# 1. `notebook_bronze` - Ingest√£o Transient ‚Üí Bronze
# 2. `notebook_silver` - Transforma√ß√£o Bronze ‚Üí Silver
# 3. `notebook_gold_dim_clientes` - Dimens√£o Clientes
# 4. `notebook_gold_dim_data` - Dimens√£o Data
# 5. `notebook_gold_dim_produtos` - Dimens√£o Produtos
# 6. `notebook_gold_fato_vendas` - Fato Vendas
# 
# **Schemas necess√°rios**:
# ```sql
# CREATE SCHEMA IF NOT EXISTS bronze;
# CREATE SCHEMA IF NOT EXISTS silver;
# CREATE SCHEMA IF NOT EXISTS gold;
# CREATE SCHEMA IF NOT EXISTS monitoramento;
# ```
# 
# ### Workflow de Execu√ß√£o:
# 
# 1. **Configurar** 
# 2. **Executar** Run All
# 3. **Acompanhar** via visualiza√ß√£o DAG
# 4. **Validar** relat√≥rio final
